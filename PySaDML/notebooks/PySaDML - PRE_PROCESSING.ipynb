{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b745f2e2-0d50-4a29-a477-58664414cd99",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div align='center'><font size=\"5\" color=\"#00000\"><center><h1 style=\"text-transform: uppercase; text-shadow: 1px 1px;\"> PySaDML </h1></center></font></div> <br>\n",
    "<div align='center'><font size=\"4\" color=\"#00000\"><center><h1 style=\"text-transform: uppercase; text-shadow: 1px 1px;\"> PRE-PROCESSING. </h1></center></font></div>\n",
    "\n",
    "<div align='center'><font size=\"2\" color=\"#00000\"><center><h1 style=\"text-transform: uppercase; text-shadow: 1px 1px;\"> Détection de son anormal dans les pièces industrielles </h1></center></font></div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54638b9",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f26cf6-337c-46e4-aec8-d998f04e2b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# =============================================================================\n",
    "# Created By  : Mike G\n",
    "# Created Date: Thursday Nov 25 15:00:00 UTC 2021\n",
    "# =============================================================================\n",
    "# Required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from include import common\n",
    "from pathlib import Path\n",
    "\n",
    "import time, datetime\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "# for plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_row', 111)\n",
    "pd.set_option('display.max_column', 111)\n",
    "\n",
    "#show pandas version\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adcaa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l'extension du fichier de données a importer.\n",
    "EXT = '.csv'\n",
    "\n",
    "# Le répertoire racine des données audio dev_data et eval_data\n",
    "DATASET_ROOT = './../data'\n",
    "\n",
    "# Les dossiers dans lesquels se trouvent les audios.\n",
    "AUDIO_SUBFOLDER = '/dev_data'\n",
    "\n",
    "# Les dossiers dans lesquels se trouvent les fichiers numpy.\n",
    "NUMPY_SUBFOLDER = '/numpy_files'\n",
    "\n",
    "DATASET_AUDIO_PATH = Path(DATASET_ROOT + AUDIO_SUBFOLDER)\n",
    "\n",
    "DATASET_NUMPY_PATH = Path(DATASET_ROOT + NUMPY_SUBFOLDER)\n",
    "\n",
    "# Si le dossier dev_data n'existe pas, le créer, sinon ne rien faire.\n",
    "Path(DATASET_AUDIO_PATH).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f628b41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!tree ./{DATASET_AUDIO_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ccb3c0",
   "metadata": {},
   "source": [
    "### 1. Chargement des données audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea373d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = common.load_metadata(DATASET_AUDIO_PATH, EXT)\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f019046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.machine_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546f6dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_machine = df.machine_type.unique()\n",
    "list_machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cfef54",
   "metadata": {},
   "source": [
    "### 2. Paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27c3ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ces paramètres sont utilisés pour extraire valeurs mel ou mfcc.\n",
    "\"\"\"\n",
    "  n_mels (integer)     - number of Mel buckets (default: 64)\n",
    "  n_mfcc (integer)     - number of MFCCs (default: 13)\n",
    "  hop_length (integer) - describes how much this window is to be shifted along the audio signal\n",
    "\n",
    "\"\"\"\n",
    "n_mels = 64\n",
    "\n",
    "n_mfcc = 40\n",
    "\n",
    "n_fft = 2**13\n",
    "\n",
    "hop_length = 2**11\n",
    "\n",
    "frame = 0\n",
    "\n",
    "sec = 0\n",
    "\n",
    "samplingrate = int(df['samplingrate'].unique()[0])\n",
    "sec_max = float(df['durations'].max())\n",
    "sec_cut = 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35047c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trunc à true siginife que les audios seront tronqués de 1s\n",
    "trunc = True\n",
    "\n",
    "# normalize à true signifie que les données mel ou mfcc extraites seront normalisées\n",
    "normalize = False\n",
    "\n",
    "# extractimage à True permet de générer des images spectrogrammes des fichiers audio\n",
    "extractimage = True\n",
    "\n",
    "# suffixe des fichiers crées et sauvegardé sur le répertoire dev_data\n",
    "suffixe = ''\n",
    "\n",
    "if trunc:\n",
    "    sec = sec_cut\n",
    "    suffixe = '_trunc.npy'\n",
    "\n",
    "if normalize:\n",
    "    sec = sec_max\n",
    "    suffixe = '_norm.npy'\n",
    "    \n",
    "if trunc & normalize:\n",
    "    sec = sec_cut\n",
    "    suffixe = '_trunc_norm.npy'\n",
    "\n",
    "frame = int((sec * samplingrate) // hop_length + 1)\n",
    "\n",
    "print(samplingrate, sec, frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b423b8",
   "metadata": {},
   "source": [
    "### 3. Extraction des caractéristiques MFCC\n",
    "\n",
    "#### 3.1 Par type de machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41ee4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_machine)):\n",
    "    # Creating empty lists for MFCC bands and labels\n",
    "    machinetype = list_machine[i]\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "    df_machine = []\n",
    "    df_machine = df[df.machine_type == machinetype]\n",
    "    df_machine.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    \n",
    "    # Iterate through all audio files and extract MFCC\n",
    "    start = time.time()\n",
    "    for j in tqdm_notebook(range(len(df_machine)), desc='Extraction des caractéristiques MFCC pour la machine '+machinetype):\n",
    "        status = df_machine.condition[j]\n",
    "\n",
    "        data_split = df_machine.data_split[j]\n",
    "        \n",
    "        # Extracting the file path\n",
    "        file_path = Path(df_machine.pathname[j])\n",
    "        \n",
    "        # Extract MFCCs\n",
    "        if trunc:\n",
    "            if normalize:\n",
    "                mfccs, sr = common.get_mfcc(file_path, hop_length, n_mels, n_mfcc, duration=sec, normalize=normalize)\n",
    "            else:\n",
    "                mfccs, sr = common.get_mfcc(file_path, hop_length, n_mels, n_mfcc, duration=sec)\n",
    "        else:\n",
    "            if normalize:\n",
    "                mfccs, sr = common.get_mfcc(file_path, hop_length, n_mels, n_mfcc, normalize=normalize)\n",
    "            else:\n",
    "                mfccs, sr = common.get_mfcc(file_path, hop_length, n_mels, n_mfcc)\n",
    "\n",
    "        if not trunc:\n",
    "            # Le tableau mfccs obtenu est la transposé du tableau obtenu par la fonction librosa mfcc \n",
    "            # car les features en sorties sont en lignes et non en colonne  \n",
    "            num_frames = mfccs.shape[1]\n",
    "\n",
    "            # Add padding to features where num_frames is inferior to frame\n",
    "            if (num_frames < frame):\n",
    "                mfccs = librosa.util.fix_length(mfccs, frame, axis=1)         \n",
    "\n",
    "        # append data and labels\n",
    "        if data_split == 'test':\n",
    "            test_data.append(mfccs)\n",
    "            test_labels.append(status)\n",
    "        else:\n",
    "            train_data.append(mfccs)\n",
    "            train_labels.append(status)\n",
    "\n",
    "        if extractimage:\n",
    "            # make a figure with the follwing figsize\n",
    "            #my_dpi=170\n",
    "            #plt.figure(figsize=(400/my_dpi, 400/my_dpi), dpi=my_dpi)\n",
    "\n",
    "            # Create spectogram image from this audio signal:\n",
    "            image_path = file_path.parent.parent.parent.parent\n",
    "            image_path = str(image_path).replace(image_path.name,'images')\n",
    "            image_path = Path(image_path,data_split, machinetype, file_path.name.replace('.wav','_mfcc.png'))\n",
    "\n",
    "            dir_dest = image_path.parent\n",
    "            dir_dest.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            #convert this melspectrogram feature into a log scaled melspectrogram\n",
    "            librosa.display.specshow(mfccs, sr=sr, y_axis='log')\n",
    "            plt.axis('off');\n",
    "\n",
    "            plt.savefig(image_path, bbox_inches='tight', pad_inches=0, format='png',dpi=100)\n",
    "            plt.clf()\n",
    "\n",
    "    # save data to disk\n",
    "    np.save(Path(DATASET_NUMPY_PATH, \"test_data_mfcc_\"+machinetype+suffixe), np.array(test_data))    \n",
    "    np.save(Path(DATASET_NUMPY_PATH, \"train_data_mfcc_\"+machinetype+suffixe), np.array(train_data))\n",
    "    #----------------------------------------------------------------------------------\n",
    "    # save label to disk\n",
    "    np.save(Path(DATASET_NUMPY_PATH, \"test_labels_\"+machinetype+\".npy\"), np.array(test_labels))\n",
    "    np.save(Path(DATASET_NUMPY_PATH, \"train_labels_\"+machinetype+\".npy\"), np.array(train_labels))\n",
    "    #----------------------------------------------------------------------------------\n",
    "    #----------------------------------------------------------------------------------\n",
    "    end = time.time()\n",
    "    duree = int(end - start)\n",
    "    print(\"La durée d'extraction est de: {}s\".format(datetime.timedelta(seconds =duree)))\n",
    "    print(\"Sauvegarde des extractions MFCC en tableau numpy.\")\n",
    "    print(\"\\tTest split: {} \\t\\t\\t Train split: {}\".format(np.array(test_data).shape[0], np.array(train_data).shape[0]))\n",
    "    print(\"\\ttest_data shape: {} \\t train_data shape: {}\".format(np.array(test_data).shape, np.array(train_data).shape))\n",
    "    print(\"\\ttest_labels shape: {} \\t\\t train_labels shape: {}\".format(np.array(test_labels).shape, np.array(train_labels).shape))\n",
    "    #----------------------------------------------------------------------------------\n",
    "    del mfccs\n",
    "    del df_machine, status, data_split, file_path   \n",
    "    del test_data, train_data, test_labels, train_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837a2fe2",
   "metadata": {},
   "source": [
    "#### 3.2 Pour l'ensembles des machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0883372",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "train_labels_type = []\n",
    "train_labels_status = []\n",
    "test_labels_type = []\n",
    "test_labels_status = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for index in tqdm_notebook(range(len(df)), desc='Extraction des caractéristiques MFCC'+suffixe):\n",
    "    machinetype = df.machine_type[index]\n",
    "    \n",
    "    status = df.condition[index]\n",
    "\n",
    "    data_split = df.data_split[index]\n",
    "\n",
    "    file_path = Path(df.pathname[index])\n",
    "\n",
    "    # Extract MFCCs\n",
    "    if trunc:\n",
    "        if normalize:\n",
    "            mfccs, sr = common.get_mfcc(file_path, hop_length, n_mels, n_mfcc, duration=sec, normalize=normalize)\n",
    "        else:\n",
    "            mfccs, sr = common.get_mfcc(file_path, hop_length, n_mels, n_mfcc, duration=sec)\n",
    "    else:\n",
    "        if normalize:\n",
    "            mfccs, sr = common.get_mfcc(file_path, hop_length, n_mels, n_mfcc, normalize=normalize)\n",
    "        else:\n",
    "            mfccs, sr = common.get_mfcc(file_path, hop_length, n_mels, n_mfcc)\n",
    "\n",
    "    if extractimage:\n",
    "        image_path = file_path.parent.parent.parent.parent\n",
    "        image_path = str(image_path).replace(image_path.name,'images')\n",
    "        image_path = Path(image_path,data_split, machinetype, file_path.name.replace('.wav','_mfcc.png'))\n",
    "\n",
    "        dir_dest = image_path.parent\n",
    "        dir_dest.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        librosa.display.specshow(mfccs, sr=sr, hop_length=hop_length, y_axis='log')\n",
    "        plt.axis('off');\n",
    "\n",
    "        plt.savefig(image_path, bbox_inches='tight', pad_inches=0, format='png',dpi=100)\n",
    "        plt.clf()\n",
    "\n",
    "    if not trunc:\n",
    "        num_frames = mfccs.shape[1]\n",
    "\n",
    "        if (num_frames < frames_max):\n",
    "            mfccs = librosa.util.fix_length(mfccs, frames_max, axis=1)         \n",
    "        \n",
    "    if data_split == 'test':\n",
    "        test_data.append(mfccs)\n",
    "        test_labels_type.append(machinetype)\n",
    "        test_labels_status.append(status)\n",
    "    else:\n",
    "        train_data.append(mfccs)\n",
    "        train_labels_type.append(machinetype)\n",
    "        train_labels_status.append(status)\n",
    "#----------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------\n",
    "# save data to disk\n",
    "np.save(Path(DATASET_NUMPY_PATH, \"test_data_mfcc\"+suffixe), np.array(test_data))    \n",
    "np.save(Path(DATASET_NUMPY_PATH, \"train_data_mfcc\"+suffixe), np.array(train_data))\n",
    "#----------------------------------------------------------------------------------\n",
    "# save label to disk\n",
    "np.save(Path(DATASET_NUMPY_PATH, \"test_labels_type.npy\"), np.array(test_labels_type))\n",
    "np.save(Path(DATASET_NUMPY_PATH, \"train_labels_type.npy\"), np.array(train_labels_type))\n",
    "np.save(Path(DATASET_NUMPY_PATH, \"test_labels_status.npy\"), np.array(test_labels_status))\n",
    "np.save(Path(DATASET_NUMPY_PATH, \"train_labels_status.npy\"), np.array(train_labels_status))\n",
    "#----------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------\n",
    "end = time.time()\n",
    "duree = int(end - start)\n",
    "print(\"La durée d'extraction est de: {}s\".format(datetime.timedelta(seconds =duree)))\n",
    "print(\"Sauvegarde des extractions MFCC en tableau numpy.\")\n",
    "print(\"\\tTest split: {} \\t\\t\\t Train split: {}\".format(np.array(test_data).shape[0], np.array(train_data).shape[0]))\n",
    "print(\"\\ttest_data shape: {} \\t train_data shape: {}\".format(np.array(test_data).shape, np.array(train_data).shape))\n",
    "print(\"\\ttest_labels_type shape: {} \\t\\t train_labels_type shape: {}\".format(np.array(test_labels_type).shape, np.array(train_labels_type).shape))\n",
    "print(\"\\ttest_labels_status shape: {} \\t\\t train_labels_status shape: {}\".format(np.array(test_labels_status).shape, np.array(train_labels_status).shape))\n",
    "#----------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------\n",
    "print(\"\\nNumber of Status: {}\".format(len(np.unique(np.array(test_labels_status)))))\n",
    "print(\"Conditions: {}\".format(np.unique(np.array(test_labels_status))))\n",
    "print(\"\\nNumber of machine type: {}\".format(len(np.unique(np.array(test_labels_type)))))\n",
    "print(\"Machine Type: {}\".format(np.unique(np.array(test_labels_type))))\n",
    "\n",
    "del mfccs\n",
    "\n",
    "del status, data_split, file_path   \n",
    "del test_data, train_data, train_labels_type, train_labels_status, test_labels_type, test_labels_status\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5d783a",
   "metadata": {},
   "source": [
    "### 4. Extraction des caractéristiques MEL\n",
    "\n",
    "#### 4.1 Par type de machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b255414",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_machine)):\n",
    "    # Creating empty lists for MFCC bands and labels\n",
    "    machinetype = list_machine[i]\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "    df_machine = []\n",
    "    df_machine = df[df.machine_type == machinetype]\n",
    "    df_machine.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    \n",
    "    # Iterate through all audio files and extract MFCC\n",
    "    start = time.time()\n",
    "    for j in tqdm_notebook(range(len(df_machine)), desc='Extraction des caractéristiques MEL pour la machine '+machinetype):\n",
    "        status = df_machine.condition[j]\n",
    "\n",
    "        data_split = df_machine.data_split[j]\n",
    "        \n",
    "        # Extracting the file path\n",
    "        file_path = Path(df_machine.pathname[j])\n",
    "        \n",
    "        # Extract MEL\n",
    "        if trunc:\n",
    "            if normalize:\n",
    "                mels, sr = common.get_mel(file_path, hop_length, n_mels, n_fft, duration=sec, normalize=normalize)\n",
    "            else:\n",
    "                mels, sr = common.get_mel(file_path, hop_length, n_mels, n_fft, duration=sec)\n",
    "        else:\n",
    "            if normalize:\n",
    "                mels, sr = common.get_mel(file_path, hop_length, n_mels, n_fft, normalize=normalize)\n",
    "            else:\n",
    "                mels, sr = common.get_mel(file_path, hop_length, n_mels, n_fft)            \n",
    "\n",
    "        if not trunc:\n",
    "            # Le tableau mfccs obtenu est la transposé du tableau obtenu par la fonction librosa mfcc \n",
    "            # car les features en sorties sont en lignes et non en colonne  \n",
    "            num_frames = mels.shape[1]\n",
    "\n",
    "            # Add padding to features where num_frames is inferior to frame\n",
    "            if (num_frames < frame):\n",
    "                mels = librosa.util.fix_length(mels, frame, axis=1)         \n",
    "\n",
    "        # append data and labels\n",
    "        if data_split == 'test':\n",
    "            test_data.append(mels)\n",
    "            test_labels.append(status)\n",
    "        else:\n",
    "            train_data.append(mels)\n",
    "            train_labels.append(status)\n",
    "\n",
    "        if extractimage:\n",
    "            image_path = file_path.parent.parent.parent.parent\n",
    "            image_path = str(image_path).replace(image_path.name,'images')\n",
    "            image_path = Path(image_path,data_split, machinetype, file_path.name.replace('.wav','_mel.png'))\n",
    "\n",
    "            dir_dest = image_path.parent\n",
    "            dir_dest.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            librosa.display.specshow(mels, sr=sr, hop_length=hop_length, y_axis='log')\n",
    "            plt.axis('off');\n",
    "\n",
    "            plt.savefig(image_path, bbox_inches='tight', pad_inches=0, format='png',dpi=100)\n",
    "            plt.clf()\n",
    "\n",
    "    # save data to disk\n",
    "    test_data_name = \"test_data_mel_\"+machinetype+suffixe\n",
    "    train_data_name = \"train_data_mel_\"+machinetype+suffixe\n",
    "    test_data_path = Path(DATASET_NUMPY_PATH, test_data_name)\n",
    "    train_data_path = Path(DATASET_NUMPY_PATH, train_data_name)\n",
    "    test_data = np.array(test_data)\n",
    "    train_data = np.array(train_data)\n",
    "    np.save(test_data_path, test_data)    \n",
    "    np.save(train_data_path, train_data)\n",
    "    #----------------------------------------------------------------------------------\n",
    "    # save label to disk\n",
    "    test_labels_name = \"test_labels_\"+machinetype+\".npy\"\n",
    "    train_labels_name = \"train_labels_\"+machinetype+\".npy\"\n",
    "    test_labels_path = Path(DATASET_NUMPY_PATH, test_labels_name)\n",
    "    train_labels_path = Path(DATASET_NUMPY_PATH, train_labels_name)\n",
    "    test_labels = np.array(test_labels)\n",
    "    np.save(test_labels_path, test_labels)\n",
    "    train_labels = np.array(train_labels)\n",
    "    np.save(train_labels_path, train_labels)\n",
    "    #----------------------------------------------------------------------------------\n",
    "    #----------------------------------------------------------------------------------\n",
    "    end = time.time()\n",
    "    duree = int(end - start)\n",
    "    print(\"La durée d'extraction est de: {}s\".format(datetime.timedelta(seconds =duree)))\n",
    "    print(\"Sauvegarde des extractions MFCC en tableau numpy.\")\n",
    "    print(\"\\tTest split: {} \\t\\t\\t Train split: {}\".format(np.array(test_data).shape[0], np.array(train_data).shape[0]))\n",
    "    print(\"\\ttest_data shape: {} \\t train_data shape: {}\".format(np.array(test_data).shape, np.array(train_data).shape))\n",
    "    print(\"\\ttest_labels shape: {} \\t\\t train_labels shape: {}\".format(np.array(test_labels).shape, np.array(train_labels).shape))\n",
    "    #----------------------------------------------------------------------------------\n",
    "    del mels\n",
    "    del df_machine, status, data_split, file_path   \n",
    "    del test_data, train_data, test_labels, train_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fe10c1",
   "metadata": {},
   "source": [
    "#### 4.2 Pour l'ensembles des machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb28cefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "train_labels_type = []\n",
    "train_labels_status = []\n",
    "test_labels_type = []\n",
    "test_labels_status = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for index in tqdm_notebook(range(len(df)), desc='Extraction des caractéristiques MFCC'+suffixe):\n",
    "    machinetype = df.machine_type[index]\n",
    "    \n",
    "    status = df.condition[index]\n",
    "\n",
    "    data_split = df.data_split[index]\n",
    "\n",
    "    file_path = Path(df.pathname[index])\n",
    "\n",
    "    # Extract MEL\n",
    "    if trunc:\n",
    "        if normalize:\n",
    "            mels, sr = common.get_mel(file_path, hop_length, n_mels, n_fft, duration=sec, normalize=normalize)\n",
    "        else:\n",
    "            mels, sr = common.get_mel(file_path, hop_length, n_mels, n_fft, duration=sec)\n",
    "    else:\n",
    "        if normalize:\n",
    "            mels, sr = common.get_mel(file_path, hop_length, n_mels, n_fft, normalize=normalize)\n",
    "        else:\n",
    "            mels, sr = common.get_mel(file_path, hop_length, n_mels, n_fft)            \n",
    "\n",
    "    if extractimage:\n",
    "        image_path = file_path.parent.parent.parent.parent\n",
    "        image_path = str(image_path).replace(image_path.name,'images')\n",
    "        image_path = Path(image_path,data_split, machinetype, file_path.name.replace('.wav','_mfcc.png'))\n",
    "\n",
    "        dir_dest = image_path.parent\n",
    "        dir_dest.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        librosa.display.specshow(mfccs, sr=sr, hop_length=hop_length, y_axis='log')\n",
    "        plt.axis('off');\n",
    "\n",
    "        plt.savefig(image_path, bbox_inches='tight', pad_inches=0, format='png',dpi=100)\n",
    "        plt.clf()\n",
    "\n",
    "    if not trunc:\n",
    "        num_frames = mels.shape[1]\n",
    "\n",
    "        if (num_frames < frames_max):\n",
    "            mels = librosa.util.fix_length(mels, frames_max, axis=1)         \n",
    "        \n",
    "    if data_split == 'test':\n",
    "        test_data.append(mels)\n",
    "        test_labels_type.append(machinetype)\n",
    "        test_labels_status.append(status)\n",
    "    else:\n",
    "        train_data.append(mels)\n",
    "        train_labels_type.append(machinetype)\n",
    "        train_labels_status.append(status)\n",
    "#----------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------\n",
    "# save data to disk\n",
    "np.save(Path(DATASET_NUMPY_PATH, \"test_data_mel\"+suffixe), np.array(test_data))    \n",
    "np.save(Path(DATASET_NUMPY_PATH, \"train_data_mel\"+suffixe), np.array(train_data))\n",
    "#----------------------------------------------------------------------------------\n",
    "# save label to disk\n",
    "np.save(Path(DATASET_NUMPY_PATH, \"test_labels_type.npy\"), np.array(test_labels_type))\n",
    "np.save(Path(DATASET_NUMPY_PATH, \"train_labels_type.npy\"), np.array(train_labels_type))\n",
    "np.save(Path(DATASET_NUMPY_PATH, \"test_labels_status.npy\"), np.array(test_labels_status))\n",
    "np.save(Path(DATASET_NUMPY_PATH, \"train_labels_status.npy\"), np.array(train_labels_status))\n",
    "#----------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------\n",
    "end = time.time()\n",
    "duree = int(end - start)\n",
    "print(\"La durée d'extraction est de: {}s\".format(datetime.timedelta(seconds =duree)))\n",
    "print(\"Sauvegarde des extractions MEL en tableau numpy.\")\n",
    "print(\"\\tTest split: {} \\t\\t\\t Train split: {}\".format(np.array(test_data).shape[0], np.array(train_data).shape[0]))\n",
    "print(\"\\ttest_data shape: {} \\t train_data shape: {}\".format(np.array(test_data).shape, np.array(train_data).shape))\n",
    "print(\"\\ttest_labels_type shape: {} \\t\\t train_labels_type shape: {}\".format(np.array(test_labels_type).shape, np.array(train_labels_type).shape))\n",
    "print(\"\\ttest_labels_status shape: {} \\t\\t train_labels_status shape: {}\".format(np.array(test_labels_status).shape, np.array(train_labels_status).shape))\n",
    "#----------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------\n",
    "print(\"\\nNumber of Status: {}\".format(len(np.unique(np.array(test_labels_status)))))\n",
    "print(\"Conditions: {}\".format(np.unique(np.array(test_labels_status))))\n",
    "print(\"\\nNumber of machine type: {}\".format(len(np.unique(np.array(test_labels_type)))))\n",
    "print(\"Machine Type: {}\".format(np.unique(np.array(test_labels_type))))\n",
    "\n",
    "del mels\n",
    "\n",
    "del status, data_split, file_path   \n",
    "del test_data, train_data, train_labels_type, train_labels_status, test_labels_type, test_labels_status\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
