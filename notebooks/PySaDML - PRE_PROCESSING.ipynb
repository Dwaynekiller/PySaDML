{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b745f2e2-0d50-4a29-a477-58664414cd99",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div align='center'><font size=\"5\" color=\"#00000\"><center><h1 style=\"text-transform: uppercase; text-shadow: 1px 1px;\"> PySaDML </h1></center></font></div> <br>\n",
    "<div align='center'><font size=\"4\" color=\"#00000\"><center><h1 style=\"text-transform: uppercase; text-shadow: 1px 1px;\"> PRE-PROCESSING. </h1></center></font></div>\n",
    "\n",
    "<div align='center'><font size=\"2\" color=\"#00000\"><center><h1 style=\"text-transform: uppercase; text-shadow: 1px 1px;\"> Détection de son anormal dans les pièces industrielles </h1></center></font></div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54638b9",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26f26cf6-337c-46e4-aec8-d998f04e2b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# =============================================================================\n",
    "# Created By  : Mike G\n",
    "# Created Date: Thursday Nov 25 15:00:00 UTC 2021\n",
    "# =============================================================================\n",
    "# Required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from include import common\n",
    "from pathlib import Path\n",
    "\n",
    "import time, datetime\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "# for plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_row', 111)\n",
    "pd.set_option('display.max_column', 111)\n",
    "\n",
    "#show pandas version\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6adcaa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l'extension du fichier de données a importer.\n",
    "EXT = '.csv'\n",
    "\n",
    "# Le répertoire racine des données audio dev_data et eval_data\n",
    "DATASET_ROOT = './../data'\n",
    "\n",
    "# Les dossiers dans lesquels se trouvent les audios.\n",
    "AUDIO_SUBFOLDER = '/dev_data'\n",
    "\n",
    "# Les dossiers dans lesquels se trouvent les fichiers numpy.\n",
    "NUMPY_SUBFOLDER = '/numpy_files'\n",
    "\n",
    "DATASET_AUDIO_PATH = Path(DATASET_ROOT + AUDIO_SUBFOLDER)\n",
    "\n",
    "DATASET_NUMPY_PATH = Path(DATASET_ROOT + NUMPY_SUBFOLDER)\n",
    "\n",
    "# Si le dossier dev_data n'existe pas, le créer, sinon ne rien faire.\n",
    "Path(DATASET_AUDIO_PATH).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f628b41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure du dossier\n",
      "Le numéro de série du volume est 50DF-2547\n",
      "C:\\USERS\\GUIDY\\DOCUMENTS\\GITHUB\\PYSADML\\DATA\\DEV_DATA\n",
      "+---fan\n",
      "¦   +---test\n",
      "¦   +---train\n",
      "+---pump\n",
      "¦   +---test\n",
      "¦   +---train\n",
      "+---slider\n",
      "¦   +---test\n",
      "¦   +---train\n",
      "+---ToyCar\n",
      "¦   +---test\n",
      "¦   +---train\n",
      "+---ToyConveyor\n",
      "¦   +---test\n",
      "¦   +---train\n",
      "+---valve\n",
      "    +---test\n",
      "    +---train\n"
     ]
    }
   ],
   "source": [
    "!tree ./{DATASET_AUDIO_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ccb3c0",
   "metadata": {},
   "source": [
    "### 1. Chargement des données audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bea373d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du fichier <dev_data.csv> des métadonnées audio...\n",
      "Terminé.\n",
      "(30987, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pathname</th>\n",
       "      <th>filename</th>\n",
       "      <th>machine_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>audio_format</th>\n",
       "      <th>machine_type</th>\n",
       "      <th>machine_kind</th>\n",
       "      <th>data_split</th>\n",
       "      <th>condition</th>\n",
       "      <th>durations</th>\n",
       "      <th>samplingrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28839</th>\n",
       "      <td>..\\data\\dev_data\\ToyConveyor\\train\\normal_id_0...</td>\n",
       "      <td>normal_id_01_00000197.wav</td>\n",
       "      <td>id_01</td>\n",
       "      <td>00000197</td>\n",
       "      <td>.wav</td>\n",
       "      <td>ToyConveyor</td>\n",
       "      <td>real_machine</td>\n",
       "      <td>train</td>\n",
       "      <td>normal</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21286</th>\n",
       "      <td>..\\data\\dev_data\\valve\\train\\normal_id_00_0000...</td>\n",
       "      <td>normal_id_00_00000313.wav</td>\n",
       "      <td>id_00</td>\n",
       "      <td>00000313</td>\n",
       "      <td>.wav</td>\n",
       "      <td>valve</td>\n",
       "      <td>real_machine</td>\n",
       "      <td>train</td>\n",
       "      <td>normal</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23822</th>\n",
       "      <td>..\\data\\dev_data\\fan\\test\\anomaly_id_00_000000...</td>\n",
       "      <td>anomaly_id_00_00000032.wav</td>\n",
       "      <td>id_00</td>\n",
       "      <td>00000032</td>\n",
       "      <td>.wav</td>\n",
       "      <td>fan</td>\n",
       "      <td>real_machine</td>\n",
       "      <td>test</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>..\\data\\dev_data\\pump\\train\\normal_id_04_00000...</td>\n",
       "      <td>normal_id_04_00000447.wav</td>\n",
       "      <td>id_04</td>\n",
       "      <td>00000447</td>\n",
       "      <td>.wav</td>\n",
       "      <td>pump</td>\n",
       "      <td>real_machine</td>\n",
       "      <td>train</td>\n",
       "      <td>normal</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22730</th>\n",
       "      <td>..\\data\\dev_data\\ToyConveyor\\test\\anomaly_id_0...</td>\n",
       "      <td>anomaly_id_03_00000152.wav</td>\n",
       "      <td>id_03</td>\n",
       "      <td>00000152</td>\n",
       "      <td>.wav</td>\n",
       "      <td>ToyConveyor</td>\n",
       "      <td>real_machine</td>\n",
       "      <td>test</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                pathname  \\\n",
       "28839  ..\\data\\dev_data\\ToyConveyor\\train\\normal_id_0...   \n",
       "21286  ..\\data\\dev_data\\valve\\train\\normal_id_00_0000...   \n",
       "23822  ..\\data\\dev_data\\fan\\test\\anomaly_id_00_000000...   \n",
       "2620   ..\\data\\dev_data\\pump\\train\\normal_id_04_00000...   \n",
       "22730  ..\\data\\dev_data\\ToyConveyor\\test\\anomaly_id_0...   \n",
       "\n",
       "                         filename machine_id sample_id audio_format  \\\n",
       "28839   normal_id_01_00000197.wav      id_01  00000197         .wav   \n",
       "21286   normal_id_00_00000313.wav      id_00  00000313         .wav   \n",
       "23822  anomaly_id_00_00000032.wav      id_00  00000032         .wav   \n",
       "2620    normal_id_04_00000447.wav      id_04  00000447         .wav   \n",
       "22730  anomaly_id_03_00000152.wav      id_03  00000152         .wav   \n",
       "\n",
       "      machine_type  machine_kind data_split condition  durations  samplingrate  \n",
       "28839  ToyConveyor  real_machine      train    normal       10.0         16000  \n",
       "21286        valve  real_machine      train    normal       10.0         16000  \n",
       "23822          fan  real_machine       test   anomaly       10.0         16000  \n",
       "2620          pump  real_machine      train    normal       10.0         16000  \n",
       "22730  ToyConveyor  real_machine       test   anomaly       10.0         16000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = common.load_metadata(DATASET_AUDIO_PATH, EXT)\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f019046a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToyConveyor    6509\n",
       "ToyCar         6459\n",
       "fan            5550\n",
       "pump           4205\n",
       "valve          4170\n",
       "slider         4094\n",
       "Name: machine_type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.machine_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "546f6dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ToyCar', 'valve', 'slider', 'pump', 'ToyConveyor', 'fan'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_machine = df.machine_type.unique()\n",
    "list_machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cfef54",
   "metadata": {},
   "source": [
    "### 2. Paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a27c3ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ces paramètres sont utilisés pour extraire valeurs mel ou mfcc.\n",
    "\"\"\"\n",
    "  n_mels (integer)     - number of Mel buckets (default: 64)\n",
    "  n_mfcc (integer)     - number of MFCCs (default: 13)\n",
    "  hop_length (integer) - describes how much this window is to be shifted along the audio signal\n",
    "\n",
    "\"\"\"\n",
    "n_mels = 64\n",
    "\n",
    "n_mfcc = 40\n",
    "\n",
    "n_fft = 2**13\n",
    "\n",
    "hop_length = 2**11\n",
    "\n",
    "frame = 0\n",
    "\n",
    "sec = 0\n",
    "\n",
    "samplingrate = int(df['samplingrate'].unique()[0])\n",
    "sec_max = float(df['durations'].max())\n",
    "sec_cut = 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35047c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000 4.0 32\n"
     ]
    }
   ],
   "source": [
    "# trunc à true siginife que les audios seront tronqués de 1s\n",
    "trunc = True\n",
    "\n",
    "# normalize à true signifie que les données mel ou mfcc extraites seront normalisées\n",
    "normalize = False\n",
    "\n",
    "# extractimage à True permet de générer des images spectrogrammes des fichiers audio\n",
    "extractimage = True\n",
    "\n",
    "# suffixe des fichiers crées et sauvegardé sur le répertoire dev_data\n",
    "suffixe = ''\n",
    "\n",
    "if trunc:\n",
    "    sec = sec_cut\n",
    "    suffixe = '_trunc.npy'\n",
    "\n",
    "if normalize:\n",
    "    sec = sec_max\n",
    "    suffixe = '_norm.npy'\n",
    "    \n",
    "if trunc & normalize:\n",
    "    sec = sec_cut\n",
    "    suffixe = '_trunc_norm.npy'\n",
    "\n",
    "frame = int((sec * samplingrate) // hop_length + 1)\n",
    "\n",
    "print(samplingrate, sec, frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b423b8",
   "metadata": {},
   "source": [
    "### 3. Extraction des caractéristiques MFCC\n",
    "\n",
    "#### 3.1 Par type de machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d41ee4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cff6db0cdbc416d93c22eaae00d2b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction des caractéristiques MFCC pour la machine ToyCar:   0%|          | 0/6459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La durée d'extraction est de: 0:00:26s\n",
      "Sauvegarde des extractions MFCC en tableau numpy.\n",
      "\tTest split: 2459 \t\t\t Train split: 4000\n",
      "\ttest_data shape: (2459, 40, 32) \t train_data shape: (4000, 40, 32)\n",
      "\ttest_labels shape: (2459,) \t\t train_labels shape: (4000,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057c7311d361420d9f44c10061276c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction des caractéristiques MFCC pour la machine valve:   0%|          | 0/4170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La durée d'extraction est de: 0:00:17s\n",
      "Sauvegarde des extractions MFCC en tableau numpy.\n",
      "\tTest split: 879 \t\t\t Train split: 3291\n",
      "\ttest_data shape: (879, 40, 32) \t train_data shape: (3291, 40, 32)\n",
      "\ttest_labels shape: (879,) \t\t train_labels shape: (3291,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a336f151b1455585dc5d534b6432b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction des caractéristiques MFCC pour la machine slider:   0%|          | 0/4094 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La durée d'extraction est de: 0:00:18s\n",
      "Sauvegarde des extractions MFCC en tableau numpy.\n",
      "\tTest split: 1290 \t\t\t Train split: 2804\n",
      "\ttest_data shape: (1290, 40, 32) \t train_data shape: (2804, 40, 32)\n",
      "\ttest_labels shape: (1290,) \t\t train_labels shape: (2804,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a840f76b8fee44c988b4bacd472c30f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction des caractéristiques MFCC pour la machine pump:   0%|          | 0/4205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La durée d'extraction est de: 0:00:17s\n",
      "Sauvegarde des extractions MFCC en tableau numpy.\n",
      "\tTest split: 856 \t\t\t Train split: 3349\n",
      "\ttest_data shape: (856, 40, 32) \t train_data shape: (3349, 40, 32)\n",
      "\ttest_labels shape: (856,) \t\t train_labels shape: (3349,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f48a89312224cabafaed0c909498445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction des caractéristiques MFCC pour la machine ToyConveyor:   0%|          | 0/6509 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La durée d'extraction est de: 0:00:26s\n",
      "Sauvegarde des extractions MFCC en tableau numpy.\n",
      "\tTest split: 3509 \t\t\t Train split: 3000\n",
      "\ttest_data shape: (3509, 40, 32) \t train_data shape: (3000, 40, 32)\n",
      "\ttest_labels shape: (3509,) \t\t train_labels shape: (3000,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa146fbbf30847d1bb0d4508a28f8e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction des caractéristiques MFCC pour la machine fan:   0%|          | 0/5550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La durée d'extraction est de: 0:00:22s\n",
      "Sauvegarde des extractions MFCC en tableau numpy.\n",
      "\tTest split: 1875 \t\t\t Train split: 3675\n",
      "\ttest_data shape: (1875, 40, 32) \t train_data shape: (3675, 40, 32)\n",
      "\ttest_labels shape: (1875,) \t\t train_labels shape: (3675,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(list_machine)):\n",
    "    # Creating empty lists for MFCC bands and labels\n",
    "    machinetype = list_machine[i]\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "    df_machine = []\n",
    "    df_machine = df[df.machine_type == machinetype]\n",
    "    df_machine.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    \n",
    "    # Iterate through all audio files and extract MFCC\n",
    "    start = time.time()\n",
    "    for j in tqdm_notebook(range(len(df_machine)), desc='Extraction des caractéristiques MFCC pour la machine '+machinetype):\n",
    "        status = df_machine.condition[j]\n",
    "\n",
    "        data_split = df_machine.data_split[j]\n",
    "        \n",
    "        # Extracting the file path\n",
    "        file_path = Path(df_machine.pathname[j])\n",
    "        \n",
    "        # Extract MFCCs\n",
    "        if trunc:\n",
    "            if normalize:\n",
    "                mfccs, sr = common.get_mfcc(file_path, hop_length, n_mels, n_mfcc, duration=sec, normalize=normalize)\n",
    "            else:\n",
    "                mfccs, sr = common.get_mfcc(file_path, hop_length, n_mels, n_mfcc, duration=sec)\n",
    "        else:\n",
    "            if normalize:\n",
    "                mfccs, sr = common.get_mfcc(file_path, hop_length, n_mels, n_mfcc, normalize=normalize)\n",
    "            else:\n",
    "                mfccs, sr = common.get_mfcc(file_path, hop_length, n_mels, n_mfcc)\n",
    "\n",
    "        if not trunc:\n",
    "            # Le tableau mfccs obtenu est la transposé du tableau obtenu par la fonction librosa mfcc \n",
    "            # car les features en sorties sont en lignes et non en colonne  \n",
    "            num_frames = mfccs.shape[1]\n",
    "\n",
    "            # Add padding to features where num_frames is inferior to frame\n",
    "            if (num_frames < frame):\n",
    "                mfccs = librosa.util.fix_length(mfccs, frame, axis=1)         \n",
    "\n",
    "        # append data and labels\n",
    "        if data_split == 'test':\n",
    "            test_data.append(mfccs)\n",
    "            test_labels.append(status)\n",
    "        else:\n",
    "            train_data.append(mfccs)\n",
    "            train_labels.append(status)\n",
    "\n",
    "        if extractimage:\n",
    "            # make a figure with the follwing figsize\n",
    "            #my_dpi=170\n",
    "            #plt.figure(figsize=(400/my_dpi, 400/my_dpi), dpi=my_dpi)\n",
    "\n",
    "            # Create spectogram image from this audio signal:\n",
    "            image_path = file_path.parent.parent.parent.parent\n",
    "            image_path = str(image_path).replace(image_path.name,'images')\n",
    "            image_path = Path(image_path,data_split, machinetype, file_path.name.replace('.wav','_mfcc.png'))\n",
    "\n",
    "            dir_dest = image_path.parent\n",
    "            dir_dest.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            #convert this melspectrogram feature into a log scaled melspectrogram\n",
    "            librosa.display.specshow(mfccs, sr=sr, y_axis='log')\n",
    "            plt.axis('off');\n",
    "\n",
    "            plt.savefig(image_path, bbox_inches='tight', pad_inches=0, format='png',dpi=100)\n",
    "            plt.clf()\n",
    "\n",
    "    # save data to disk\n",
    "    np.save(Path(DATASET_NUMPY_PATH, \"test_data_mfcc_\"+machinetype+suffixe), np.array(test_data))    \n",
    "    np.save(Path(DATASET_NUMPY_PATH, \"train_data_mfcc_\"+machinetype+suffixe), np.array(train_data))\n",
    "    #----------------------------------------------------------------------------------\n",
    "    # save label to disk\n",
    "    np.save(Path(DATASET_NUMPY_PATH, \"test_labels_\"+machinetype+\".npy\"), np.array(test_labels))\n",
    "    np.save(Path(DATASET_NUMPY_PATH, \"train_labels_\"+machinetype+\".npy\"), np.array(train_labels))\n",
    "    #----------------------------------------------------------------------------------\n",
    "    #----------------------------------------------------------------------------------\n",
    "    end = time.time()\n",
    "    duree = int(end - start)\n",
    "    print(\"La durée d'extraction est de: {}s\".format(datetime.timedelta(seconds =duree)))\n",
    "    print(\"Sauvegarde des extractions MFCC en tableau numpy.\")\n",
    "    print(\"\\tTest split: {} \\t\\t\\t Train split: {}\".format(np.array(test_data).shape[0], np.array(train_data).shape[0]))\n",
    "    print(\"\\ttest_data shape: {} \\t train_data shape: {}\".format(np.array(test_data).shape, np.array(train_data).shape))\n",
    "    print(\"\\ttest_labels shape: {} \\t\\t train_labels shape: {}\".format(np.array(test_labels).shape, np.array(train_labels).shape))\n",
    "    #----------------------------------------------------------------------------------\n",
    "    #----------------------------------------------------------------------------------\n",
    "    print(\"\\nNumber of Status: {}\".format(len(np.unique(np.array(test_labels_status)))))\n",
    "    print(\"Conditions: {}\".format(np.unique(np.array(test_labels_status))))\n",
    "    print(\"\\nNumber of machine type: {}\".format(len(np.unique(np.array(test_labels_type)))))\n",
    "    print(\"Machine Type: {}\".format(np.unique(np.array(test_labels_type))))\n",
    "    #----------------------------------------------------------------------------------\n",
    "    #----------------------------------------------------------------------------------\n",
    "    del mfccs\n",
    "    del df_machine, status, data_split, file_path   \n",
    "    del test_data, train_data, test_labels, train_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837a2fe2",
   "metadata": {},
   "source": [
    "#### 3.2 Pour l'ensembles des machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0883372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2865e3ded9a49c08f2fdcdd7343f74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction des caractéristiques MFCC_trunc.npy:   0%|          | 0/30987 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La durée d'extraction est de: 0:35:48s\n",
      "Sauvegarde des extractions MFCC en tableau numpy.\n",
      "\tTest split: 10868 \t\t\t Train split: 20119\n",
      "\ttest_data shape: (10868, 40, 32) \t train_data shape: (20119, 40, 32)\n",
      "\ttest_labels_type shape: (10868,) \t\t train_labels_type shape: (20119,)\n",
      "\ttest_labels_status shape: (10868,) \t\t train_labels_status shape: (20119,)\n",
      "\n",
      "Number of Status: 2\n",
      "Conditions: ['anomaly' 'normal']\n",
      "\n",
      "Number of machine type: 6\n",
      "Machine Type: ['ToyCar' 'ToyConveyor' 'fan' 'pump' 'slider' 'valve']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "train_labels_type = []\n",
    "train_labels_status = []\n",
    "test_labels_type = []\n",
    "test_labels_status = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for index in tqdm_notebook(range(len(df)), desc='Extraction des caractéristiques MFCC'+suffixe):\n",
    "    machinetype = df.machine_type[index]\n",
    "    \n",
    "    status = df.condition[index]\n",
    "\n",
    "    data_split = df.data_split[index]\n",
    "\n",
    "    file_path = Path(df.pathname[index])\n",
    "\n",
    "    # Extract MFCCs\n",
    "    if trunc:\n",
    "        if normalize:\n",
    "            mfccs, sr = common.get_mfcc(file_path, hop_length, n_mels, n_mfcc, duration=sec, normalize=normalize)\n",
    "        else:\n",
    "            mfccs, sr = common.get_mfcc(file_path, hop_length, n_mels, n_mfcc, duration=sec)\n",
    "    else:\n",
    "        if normalize:\n",
    "            mfccs, sr = common.get_mfcc(file_path, hop_length, n_mels, n_mfcc, normalize=normalize)\n",
    "        else:\n",
    "            mfccs, sr = common.get_mfcc(file_path, hop_length, n_mels, n_mfcc)\n",
    "\n",
    "    if extractimage:\n",
    "        image_path = file_path.parent.parent.parent.parent\n",
    "        image_path = str(image_path).replace(image_path.name,'images')\n",
    "        image_path = Path(image_path,data_split, machinetype, file_path.name.replace('.wav','_mfcc.png'))\n",
    "\n",
    "        dir_dest = image_path.parent\n",
    "        dir_dest.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        librosa.display.specshow(mfccs, sr=sr, hop_length=hop_length, y_axis='log')\n",
    "        plt.axis('off');\n",
    "\n",
    "        plt.savefig(image_path, bbox_inches='tight', pad_inches=0, format='png',dpi=100)\n",
    "        plt.clf()\n",
    "\n",
    "    if not trunc:\n",
    "        num_frames = mfccs.shape[1]\n",
    "\n",
    "        if (num_frames < frames_max):\n",
    "            mfccs = librosa.util.fix_length(mfccs, frames_max, axis=1)         \n",
    "        \n",
    "    if data_split == 'test':\n",
    "        test_data.append(mfccs)\n",
    "        test_labels_type.append(machinetype)\n",
    "        test_labels_status.append(status)\n",
    "    else:\n",
    "        train_data.append(mfccs)\n",
    "        train_labels_type.append(machinetype)\n",
    "        train_labels_status.append(status)\n",
    "#----------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------\n",
    "# save data to disk\n",
    "np.save(Path(DATASET_NUMPY_PATH, \"test_data_mfcc\"+suffixe), np.array(test_data))    \n",
    "np.save(Path(DATASET_NUMPY_PATH, \"train_data_mfcc\"+suffixe), np.array(train_data))\n",
    "#----------------------------------------------------------------------------------\n",
    "# save label to disk\n",
    "np.save(Path(DATASET_NUMPY_PATH, \"test_labels_type.npy\"), np.array(test_labels_type))\n",
    "np.save(Path(DATASET_NUMPY_PATH, \"train_labels_type.npy\"), np.array(train_labels_type))\n",
    "np.save(Path(DATASET_NUMPY_PATH, \"test_labels_status.npy\"), np.array(test_labels_status))\n",
    "np.save(Path(DATASET_NUMPY_PATH, \"train_labels_status.npy\"), np.array(train_labels_status))\n",
    "#----------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------\n",
    "end = time.time()\n",
    "duree = int(end - start)\n",
    "print(\"La durée d'extraction est de: {}s\".format(datetime.timedelta(seconds =duree)))\n",
    "print(\"Sauvegarde des extractions MFCC en tableau numpy.\")\n",
    "print(\"\\tTest split: {} \\t\\t\\t Train split: {}\".format(np.array(test_data).shape[0], np.array(train_data).shape[0]))\n",
    "print(\"\\ttest_data shape: {} \\t train_data shape: {}\".format(np.array(test_data).shape, np.array(train_data).shape))\n",
    "print(\"\\ttest_labels_type shape: {} \\t\\t train_labels_type shape: {}\".format(np.array(test_labels_type).shape, np.array(train_labels_type).shape))\n",
    "print(\"\\ttest_labels_status shape: {} \\t\\t train_labels_status shape: {}\".format(np.array(test_labels_status).shape, np.array(train_labels_status).shape))\n",
    "#----------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------\n",
    "print(\"\\nNumber of Status: {}\".format(len(np.unique(np.array(test_labels_status)))))\n",
    "print(\"Conditions: {}\".format(np.unique(np.array(test_labels_status))))\n",
    "print(\"\\nNumber of machine type: {}\".format(len(np.unique(np.array(test_labels_type)))))\n",
    "print(\"Machine Type: {}\".format(np.unique(np.array(test_labels_type))))\n",
    "\n",
    "del mfccs\n",
    "\n",
    "del status, data_split, file_path   \n",
    "del test_data, train_data, train_labels_type, train_labels_status, test_labels_type, test_labels_status\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5d783a",
   "metadata": {},
   "source": [
    "### 4. Extraction des caractéristiques MEL\n",
    "\n",
    "#### 4.1 Par type de machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b255414",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_machine)):\n",
    "    # Creating empty lists for MFCC bands and labels\n",
    "    machinetype = list_machine[i]\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "    df_machine = []\n",
    "    df_machine = df[df.machine_type == machinetype]\n",
    "    df_machine.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    \n",
    "    # Iterate through all audio files and extract MFCC\n",
    "    start = time.time()\n",
    "    for j in tqdm_notebook(range(len(df_machine)), desc='Extraction des caractéristiques MEL pour la machine '+machinetype):\n",
    "        status = df_machine.condition[j]\n",
    "\n",
    "        data_split = df_machine.data_split[j]\n",
    "        \n",
    "        # Extracting the file path\n",
    "        file_path = Path(df_machine.pathname[j])\n",
    "        \n",
    "        # Extract MEL\n",
    "        if trunc:\n",
    "            if normalize:\n",
    "                mels, sr = common.get_mel(file_path, hop_length, n_mels, n_fft, duration=sec, normalize=normalize)\n",
    "            else:\n",
    "                mels, sr = common.get_mel(file_path, hop_length, n_mels, n_fft, duration=sec)\n",
    "        else:\n",
    "            if normalize:\n",
    "                mels, sr = common.get_mel(file_path, hop_length, n_mels, n_fft, normalize=normalize)\n",
    "            else:\n",
    "                mels, sr = common.get_mel(file_path, hop_length, n_mels, n_fft)            \n",
    "\n",
    "        if not trunc:\n",
    "            # Le tableau mfccs obtenu est la transposé du tableau obtenu par la fonction librosa mfcc \n",
    "            # car les features en sorties sont en lignes et non en colonne  \n",
    "            num_frames = mels.shape[1]\n",
    "\n",
    "            # Add padding to features where num_frames is inferior to frame\n",
    "            if (num_frames < frame):\n",
    "                mels = librosa.util.fix_length(mels, frame, axis=1)         \n",
    "\n",
    "        # append data and labels\n",
    "        if data_split == 'test':\n",
    "            test_data.append(mels)\n",
    "            test_labels.append(status)\n",
    "        else:\n",
    "            train_data.append(mels)\n",
    "            train_labels.append(status)\n",
    "\n",
    "        if extractimage:\n",
    "            image_path = file_path.parent.parent.parent.parent\n",
    "            image_path = str(image_path).replace(image_path.name,'images')\n",
    "            image_path = Path(image_path,data_split, machinetype, file_path.name.replace('.wav','_mel.png'))\n",
    "\n",
    "            dir_dest = image_path.parent\n",
    "            dir_dest.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            librosa.display.specshow(mels, sr=sr, hop_length=hop_length, y_axis='log')\n",
    "            plt.axis('off');\n",
    "\n",
    "            plt.savefig(image_path, bbox_inches='tight', pad_inches=0, format='png',dpi=100)\n",
    "            plt.clf()\n",
    "\n",
    "    # save data to disk\n",
    "    test_data_name = \"test_data_mel_\"+machinetype+suffixe\n",
    "    train_data_name = \"train_data_mel_\"+machinetype+suffixe\n",
    "    test_data_path = Path(DATASET_NUMPY_PATH, test_data_name)\n",
    "    train_data_path = Path(DATASET_NUMPY_PATH, train_data_name)\n",
    "    test_data = np.array(test_data)\n",
    "    train_data = np.array(train_data)\n",
    "    np.save(test_data_path, test_data)    \n",
    "    np.save(train_data_path, train_data)\n",
    "    #----------------------------------------------------------------------------------\n",
    "    # save label to disk\n",
    "    test_labels_name = \"test_labels_\"+machinetype+\".npy\"\n",
    "    train_labels_name = \"train_labels_\"+machinetype+\".npy\"\n",
    "    test_labels_path = Path(DATASET_NUMPY_PATH, test_labels_name)\n",
    "    train_labels_path = Path(DATASET_NUMPY_PATH, train_labels_name)\n",
    "    test_labels = np.array(test_labels)\n",
    "    np.save(test_labels_path, test_labels)\n",
    "    train_labels = np.array(train_labels)\n",
    "    np.save(train_labels_path, train_labels)\n",
    "    #----------------------------------------------------------------------------------\n",
    "    #----------------------------------------------------------------------------------\n",
    "    end = time.time()\n",
    "    duree = int(end - start)\n",
    "    print(\"La durée d'extraction est de: {}s\".format(datetime.timedelta(seconds =duree)))\n",
    "    print(\"Sauvegarde des extractions MFCC en tableau numpy.\")\n",
    "    print(\"\\tTest split: {} \\t\\t\\t Train split: {}\".format(np.array(test_data).shape[0], np.array(train_data).shape[0]))\n",
    "    print(\"\\ttest_data shape: {} \\t train_data shape: {}\".format(np.array(test_data).shape, np.array(train_data).shape))\n",
    "    print(\"\\ttest_labels shape: {} \\t\\t train_labels shape: {}\".format(np.array(test_labels).shape, np.array(train_labels).shape))\n",
    "    #----------------------------------------------------------------------------------\n",
    "    #----------------------------------------------------------------------------------\n",
    "    print(\"\\nNumber of Status: {}\".format(len(np.unique(np.array(test_labels_status)))))\n",
    "    print(\"Conditions: {}\".format(np.unique(np.array(test_labels_status))))\n",
    "    print(\"\\nNumber of machine type: {}\".format(len(np.unique(np.array(test_labels_type)))))\n",
    "    print(\"Machine Type: {}\".format(np.unique(np.array(test_labels_type))))\n",
    "    #----------------------------------------------------------------------------------\n",
    "    #----------------------------------------------------------------------------------\n",
    "    del mels\n",
    "    del df_machine, status, data_split, file_path   \n",
    "    del test_data, train_data, test_labels, train_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fe10c1",
   "metadata": {},
   "source": [
    "#### 4.2 Pour l'ensembles des machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb28cefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "train_labels_type = []\n",
    "train_labels_status = []\n",
    "test_labels_type = []\n",
    "test_labels_status = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for index in tqdm_notebook(range(len(df)), desc='Extraction des caractéristiques MFCC'+suffixe):\n",
    "    machinetype = df.machine_type[index]\n",
    "    \n",
    "    status = df.condition[index]\n",
    "\n",
    "    data_split = df.data_split[index]\n",
    "\n",
    "    file_path = Path(df.pathname[index])\n",
    "\n",
    "    # Extract MEL\n",
    "    if trunc:\n",
    "        if normalize:\n",
    "            mels, sr = common.get_mel(file_path, hop_length, n_mels, n_fft, duration=sec, normalize=normalize)\n",
    "        else:\n",
    "            mels, sr = common.get_mel(file_path, hop_length, n_mels, n_fft, duration=sec)\n",
    "    else:\n",
    "        if normalize:\n",
    "            mels, sr = common.get_mel(file_path, hop_length, n_mels, n_fft, normalize=normalize)\n",
    "        else:\n",
    "            mels, sr = common.get_mel(file_path, hop_length, n_mels, n_fft)            \n",
    "\n",
    "    if extractimage:\n",
    "        image_path = file_path.parent.parent.parent.parent\n",
    "        image_path = str(image_path).replace(image_path.name,'images')\n",
    "        image_path = Path(image_path,data_split, machinetype, file_path.name.replace('.wav','_mfcc.png'))\n",
    "\n",
    "        dir_dest = image_path.parent\n",
    "        dir_dest.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        librosa.display.specshow(mfccs, sr=sr, hop_length=hop_length, y_axis='log')\n",
    "        plt.axis('off');\n",
    "\n",
    "        plt.savefig(image_path, bbox_inches='tight', pad_inches=0, format='png',dpi=100)\n",
    "        plt.clf()\n",
    "\n",
    "    if not trunc:\n",
    "        num_frames = mels.shape[1]\n",
    "\n",
    "        if (num_frames < frames_max):\n",
    "            mels = librosa.util.fix_length(mels, frames_max, axis=1)         \n",
    "        \n",
    "    if data_split == 'test':\n",
    "        test_data.append(mels)\n",
    "        test_labels_type.append(machinetype)\n",
    "        test_labels_status.append(status)\n",
    "    else:\n",
    "        train_data.append(mels)\n",
    "        train_labels_type.append(machinetype)\n",
    "        train_labels_status.append(status)\n",
    "#----------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------\n",
    "# save data to disk\n",
    "np.save(Path(DATASET_NUMPY_PATH, \"test_data_mel\"+suffixe), np.array(test_data))    \n",
    "np.save(Path(DATASET_NUMPY_PATH, \"train_data_mel\"+suffixe), np.array(train_data))\n",
    "#----------------------------------------------------------------------------------\n",
    "# save label to disk\n",
    "np.save(Path(DATASET_NUMPY_PATH, \"test_labels_type.npy\"), np.array(test_labels_type))\n",
    "np.save(Path(DATASET_NUMPY_PATH, \"train_labels_type.npy\"), np.array(train_labels_type))\n",
    "np.save(Path(DATASET_NUMPY_PATH, \"test_labels_status.npy\"), np.array(test_labels_status))\n",
    "np.save(Path(DATASET_NUMPY_PATH, \"train_labels_status.npy\"), np.array(train_labels_status))\n",
    "#----------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------\n",
    "end = time.time()\n",
    "duree = int(end - start)\n",
    "print(\"La durée d'extraction est de: {}s\".format(datetime.timedelta(seconds =duree)))\n",
    "print(\"Sauvegarde des extractions MEL en tableau numpy.\")\n",
    "print(\"\\tTest split: {} \\t\\t\\t Train split: {}\".format(np.array(test_data).shape[0], np.array(train_data).shape[0]))\n",
    "print(\"\\ttest_data shape: {} \\t train_data shape: {}\".format(np.array(test_data).shape, np.array(train_data).shape))\n",
    "print(\"\\ttest_labels_type shape: {} \\t\\t train_labels_type shape: {}\".format(np.array(test_labels_type).shape, np.array(train_labels_type).shape))\n",
    "print(\"\\ttest_labels_status shape: {} \\t\\t train_labels_status shape: {}\".format(np.array(test_labels_status).shape, np.array(train_labels_status).shape))\n",
    "#----------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------\n",
    "print(\"\\nNumber of Status: {}\".format(len(np.unique(np.array(test_labels_status)))))\n",
    "print(\"Conditions: {}\".format(np.unique(np.array(test_labels_status))))\n",
    "print(\"\\nNumber of machine type: {}\".format(len(np.unique(np.array(test_labels_type)))))\n",
    "print(\"Machine Type: {}\".format(np.unique(np.array(test_labels_type))))\n",
    "\n",
    "del mels\n",
    "\n",
    "del status, data_split, file_path   \n",
    "del test_data, train_data, train_labels_type, train_labels_status, test_labels_type, test_labels_status\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
